import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
import sys
from PIL import Image
from io import BytesIO

# Add the current directory to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import the StrokeShield class
from strokeshield_prediction import StrokeShield

# Print debug information
print(f"Current working directory: {os.getcwd()}")
print(f"Dataset exists: {os.path.exists('data/healthcare-dataset-stroke-data.csv')}")
print(f"RF model exists: {os.path.exists('models/random_forest_model.pkl')}")
print(f"LR model exists: {os.path.exists('models/logistic_regression_model.pkl')}")

# Set page configuration
st.set_page_config(
    page_title="StrokeShield - Stroke Prediction System",
    page_icon="ðŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Add CSS for styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #4A4A4A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #4A4A4A;
        margin-bottom: 1rem;
    }
    .info-text {
        font-size: 1rem;
        color: #666666;
    }
    .highlight {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .prediction-box {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-top: 1rem;
        text-align: center;
    }
    .prediction-header {
        font-size: 1.2rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    .high-risk {
        color: #ff4b4b;
        font-weight: bold;
    }
    .low-risk {
        color: #00cc96;
        font-weight: bold;
    }
    .medium-risk {
        color: #ffa15a;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_data
def load_dataset():
    """Load the stroke dataset"""
    try:
        # Check multiple possible locations for the dataset
        possible_paths = [
            "data/healthcare-dataset-stroke-data.csv",
            "./data/healthcare-dataset-stroke-data.csv",
            "../data/healthcare-dataset-stroke-data.csv",
            "healthcare-dataset-stroke-data.csv",
            "./healthcare-dataset-stroke-data.csv"
        ]

        for path in possible_paths:
            if os.path.exists(path):
                print(f"Found dataset at: {path}")
                df = pd.read_csv(path)
                return df

        st.error("Error: Dataset not found. Please make sure the dataset file exists.")
        return None
    except Exception as e:
        st.error(f"Error loading dataset: {e}")
        return None


@st.cache_resource
def load_stroke_shield_models():
    """Load the trained models"""
    try:
        # Check multiple possible locations for the models
        rf_paths = [
            "models/random_forest_model.pkl",
            "./models/random_forest_model.pkl",
            "../models/random_forest_model.pkl",
            "random_forest_model.pkl",
            "./random_forest_model.pkl"
        ]

        lr_paths = [
            "models/logistic_regression_model.pkl",
            "./models/logistic_regression_model.pkl",
            "../models/logistic_regression_model.pkl",
            "logistic_regression_model.pkl",
            "./logistic_regression_model.pkl"
        ]

        rf_path = None
        lr_path = None

        # Find model files
        for path in rf_paths:
            if os.path.exists(path):
                rf_path = path
                print(f"Found RF model at: {path}")
                break

        for path in lr_paths:
            if os.path.exists(path):
                lr_path = path
                print(f"Found LR model at: {path}")
                break

        if rf_path and lr_path:
            # Load existing models
            shield = StrokeShield()
            shield.load_models(rf_path, lr_path)
            return shield
        else:
            st.warning("Models not found. Training new models...")

            # Initialize StrokeShield
            shield = StrokeShield()

            # Load data
            df = load_dataset()

            if df is not None:
                # Train models
                shield.data = df
                shield.preprocess_data()
                shield.train_random_forest()
                shield.train_logistic_regression()

                # Create models directory if it doesn't exist
                os.makedirs("models", exist_ok=True)

                # Save models
                shield.save_models("models/random_forest_model.pkl", "models/logistic_regression_model.pkl")

                return shield
            else:
                return None
    except Exception as e:
        st.error(f"Error loading models: {e}")
        return None


def create_feature_importance_plot(shield):
    """Create a feature importance plot"""
    if shield.rf_model is None:
        return None

    try:
        # Get feature names from preprocessor
        cat_features = shield.rf_model.named_steps['preprocessor'].transformers_[1][2]
        cat_feature_names = shield.rf_model.named_steps['preprocessor'].transformers_[1][1][
            'onehot'].get_feature_names_out(cat_features)

        num_features = shield.rf_model.named_steps['preprocessor'].transformers_[0][2]

        feature_names = list(num_features) + list(cat_feature_names)

        # Get feature importances
        importances = shield.rf_model.named_steps['classifier'].feature_importances_

        # Sort feature importances
        indices = np.argsort(importances)[-15:]  # Get the top 15 features

        # Create plot
        fig, ax = plt.subplots(figsize=(10, 8))
        plt.barh(range(len(indices)), importances[indices], align='center')
        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
        plt.xlabel('Feature Importance')
        plt.title('Top 15 Most Important Features')
        plt.tight_layout()

        return fig
    except Exception as e:
        print(f"Error creating feature importance plot: {e}")
        return None


def create_age_plot(df):
    """Create an age distribution plot"""
    try:
        fig, ax = plt.subplots(figsize=(10, 6))

        # Create histogram with KDE
        sns.histplot(data=df, x='age', hue='stroke', kde=True, palette=['#4f8ff7', '#ff5959'], bins=30, ax=ax)

        # Set labels
        ax.set_xlabel('Age')
        ax.set_ylabel('Count')
        ax.set_title('Age Distribution by Stroke Occurrence')

        # Add legend
        ax.legend(['No Stroke', 'Stroke'])

        plt.tight_layout()
        return fig
    except Exception as e:
        print(f"Error creating age plot: {e}")
        return None


def create_correlation_heatmap(df):
    """Create a correlation heatmap"""
    try:
        # Select only numeric columns
        numeric_df = df.select_dtypes(include=['int64', 'float64'])

        # Compute correlation matrix
        corr = numeric_df.corr()

        # Create heatmap
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)
        ax.set_title('Correlation Matrix of Numeric Features')

        plt.tight_layout()
        return fig
    except Exception as e:
        print(f"Error creating correlation heatmap: {e}")
        return None


def main():
    """Main function for the Streamlit app"""

    # Display header
    st.markdown("<h1 class='main-header'>StrokeShield: Advanced Stroke Prediction System</h1>", unsafe_allow_html=True)

    # Load dataset
    df = load_dataset()

    # Load models
    shield = load_stroke_shield_models()

    # Sidebar
    st.sidebar.image("https://img.icons8.com/color/96/000000/brain.png", width=100)
    st.sidebar.title("Navigation")

    # Define pages
    pages = ["Home", "Data Exploration", "Risk Assessment", "Model Performance"]
    selected_page = st.sidebar.radio("Go to", pages)

    # Load data for all pages
    if df is None or shield is None:
        st.error("Error: Could not load data or models. Please check the console for details.")
        return

    # HOME PAGE
    if selected_page == "Home":
        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("<div class='highlight'>", unsafe_allow_html=True)
            st.markdown("<h2 class='sub-header'>Welcome to StrokeShield</h2>", unsafe_allow_html=True)
            st.markdown("""
            StrokeShield is an advanced stroke prediction system built using machine learning techniques. 
            The system combines Random Forest and Logistic Regression models to predict stroke risk 
            with high accuracy (90%+) based on various health parameters and demographic factors.

            ### Key Features:
            - **Data-driven predictions** based on a dataset of 5,000+ patients
            - **Dual model approach** combining Random Forest and Logistic Regression algorithms
            - **Feature importance analysis** to identify key stroke risk factors
            - **User-friendly interface** for healthcare professionals and researchers
            - **High accuracy** in stroke risk prediction
            """)
            st.markdown("</div>", unsafe_allow_html=True)

            st.markdown("<h2 class='sub-header'>How It Works</h2>", unsafe_allow_html=True)
            st.markdown("<div class='highlight'>", unsafe_allow_html=True)
            st.markdown("""
            StrokeShield works by analyzing multiple risk factors associated with stroke occurrence. 
            The system has been trained on a comprehensive dataset containing various health metrics 
            and demographic information. By identifying patterns in this data, the models can predict 
            the likelihood of stroke for new patients.

            ### Workflow:
            1. **Data Collection**: Patient health data including age, gender, hypertension status, heart disease, glucose levels, BMI, etc.
            2. **Data Preprocessing**: Handling missing values, encoding categorical features, and scaling numeric features
            3. **Model Training**: Training multiple machine learning models on the processed data
            4. **Model Evaluation**: Assessing model performance using metrics like accuracy, precision, and recall
            5. **Risk Prediction**: Combining model predictions to provide a final stroke risk assessment
            """)
            st.markdown("</div>", unsafe_allow_html=True)

        with col2:
            st.markdown("<div class='highlight'>", unsafe_allow_html=True)
            st.markdown("<h3 class='sub-header'>Stroke: Quick Facts</h3>", unsafe_allow_html=True)
            st.markdown("""
            - Stroke is the 2nd leading cause of death globally
            - Every 40 seconds, someone in the US has a stroke
            - Up to 80% of strokes are preventable
            - Early detection and intervention are critical
            - Risk factors include high blood pressure, smoking, diabetes, and high cholesterol
            """)
            st.markdown("</div>", unsafe_allow_html=True)

            st.markdown("<div class='highlight'>", unsafe_allow_html=True)
            st.markdown("<h3 class='sub-header'>Get Started</h3>", unsafe_allow_html=True)
            st.markdown("""
            - Explore the dataset in the **Data Exploration** section
            - Assess stroke risk in the **Risk Assessment** section
            - Learn about model performance in the **Model Performance** section
            """)
            st.markdown("</div>", unsafe_allow_html=True)

    # DATA EXPLORATION PAGE
    elif selected_page == "Data Exploration":
        st.markdown("<h2 class='sub-header'>Data Exploration</h2>", unsafe_allow_html=True)

        # Dataset overview
        st.markdown("<div class='highlight'>", unsafe_allow_html=True)
        st.markdown("<h3>Dataset Overview</h3>", unsafe_allow_html=True)

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total Patients", f"{df.shape[0]:,}")
            st.metric("Features", f"{df.shape[1] - 1}")  # Excluding the target variable

        with col2:
            stroke_count = df['stroke'].sum()
            stroke_percentage = (stroke_count / df.shape[0]) * 100
            st.metric("Stroke Cases", f"{stroke_count:,}")
            st.metric("Stroke Percentage", f"{stroke_percentage:.2f}%")

        st.markdown("</div>", unsafe_allow_html=True)

        # Data sample
        st.markdown("<h3>Data Sample</h3>", unsafe_allow_html=True)
        st.dataframe(df.head(10))

        # Visualizations
        st.markdown("<h3>Visualizations</h3>", unsafe_allow_html=True)

        tab1, tab2, tab3 = st.tabs(["Age Distribution", "Feature Correlations", "Feature Importance"])

        with tab1:
            age_fig = create_age_plot(df)
            if age_fig:
                st.pyplot(age_fig)
                st.markdown("""
                The age distribution shows that stroke risk increases significantly with age. 
                Older patients have a much higher incidence of stroke compared to younger patients.
                """)

        with tab2:
            corr_fig = create_correlation_heatmap(df)
            if corr_fig:
                st.pyplot(corr_fig)
                st.markdown("""
                The correlation matrix shows relationships between numeric features. 
                Age has the strongest positive correlation with stroke occurrence.
                """)

        with tab3:
            if shield is not None:
                imp_fig = create_feature_importance_plot(shield)
                if imp_fig is not None:
                    st.pyplot(imp_fig)
                    st.markdown("""
                    The feature importance plot shows which factors most strongly influence stroke prediction.
                    Age, glucose level, and hypertension are among the most important predictors.
                    """)

    # RISK ASSESSMENT PAGE
    elif selected_page == "Risk Assessment":
        st.markdown("<h2 class='sub-header'>Stroke Risk Assessment</h2>", unsafe_allow_html=True)

        st.markdown("""
        Enter patient information below to predict stroke risk. The system will analyze the data
        using both Random Forest and Logistic Regression models, then provide a combined assessment.
        """)

        # Create columns for form inputs
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("<div class='highlight'>", unsafe_allow_html=True)
            st.markdown("<h3>Personal Information</h3>", unsafe_allow_html=True)

            gender = st.selectbox("Gender", ["Male", "Female", "Other"])
            age = st.slider("Age", 18, 100, 50)
            ever_married = st.selectbox("Ever Married", ["Yes", "No"])
            work_type = st.selectbox("Work Type", ["Private", "Self-employed", "Govt_job", "children", "Never_worked"])
            residence_type = st.selectbox("Residence Type", ["Urban", "Rural"])

            st.markdown("</div>", unsafe_allow_html=True)

        with col2:
            st.markdown("<div class='highlight'>", unsafe_allow_html=True)
            st.markdown("<h3>Health Information</h3>", unsafe_allow_html=True)

            hypertension = st.selectbox("Hypertension", ["No", "Yes"])
            heart_disease = st.selectbox("Heart Disease", ["No", "Yes"])
            avg_glucose_level = st.slider("Average Glucose Level (mg/dL)", 50.0, 300.0, 100.0)
            bmi = st.slider("BMI", 10.0, 50.0, 25.0)
            smoking_status = st.selectbox("Smoking Status", ["never smoked", "formerly smoked", "smokes", "Unknown"])

            st.markdown("</div>", unsafe_allow_html=True)

        # Predict button
        if st.button("Predict Stroke Risk"):
            try:
                # Prepare input data
                patient_data = {
                    'gender': gender,
                    'age': age,
                    'hypertension': 1 if hypertension == "Yes" else 0,
                    'heart_disease': 1 if heart_disease == "Yes" else 0,
                    'ever_married': ever_married,
                    'work_type': work_type,
                    'Residence_type': residence_type,
                    'avg_glucose_level': avg_glucose_level,
                    'bmi': bmi,
                    'smoking_status': smoking_status
                }

                # Make prediction
                result = shield.predict_stroke_risk(patient_data)

                # Display prediction
                st.markdown("<div class='prediction-box'>", unsafe_allow_html=True)

                st.markdown("<h3 class='prediction-header'>Stroke Risk Assessment</h3>", unsafe_allow_html=True)

                # Calculate risk level
                risk_prob = result['ensemble']['probability']
                if risk_prob < 0.2:
                    risk_level = "Low"
                    risk_class = "low-risk"
                elif risk_prob < 0.5:
                    risk_level = "Medium"
                    risk_class = "medium-risk"
                else:
                    risk_level = "High"
                    risk_class = "high-risk"

                # Display risk
                st.markdown(f"<h2 class='{risk_class}'>Risk Level: {risk_level} ({risk_prob:.1%})</h2>",
                            unsafe_allow_html=True)

                # Display model details
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("<h4>Random Forest Model</h4>", unsafe_allow_html=True)
                    rf_prob = result['random_forest']['probability']
                    rf_class = "high-risk" if rf_prob >= 0.5 else "medium-risk" if rf_prob >= 0.2 else "low-risk"
                    st.markdown(f"<p class='{rf_class}'>Stroke Probability: {rf_prob:.1%}</p>", unsafe_allow_html=True)

                with col2:
                    st.markdown("<h4>Logistic Regression Model</h4>", unsafe_allow_html=True)
                    lr_prob = result['logistic_regression']['probability']
                    lr_class = "high-risk" if lr_prob >= 0.5 else "medium-risk" if lr_prob >= 0.2 else "low-risk"
                    st.markdown(f"<p class='{lr_class}'>Stroke Probability: {lr_prob:.1%}</p>", unsafe_allow_html=True)

                # Risk factors
                st.markdown("<h4>Key Risk Factors:</h4>", unsafe_allow_html=True)

                risk_factors = []

                if age > 65:
                    risk_factors.append("Advanced age (over 65 years)")
                if hypertension == "Yes":
                    risk_factors.append("Hypertension")
                if heart_disease == "Yes":
                    risk_factors.append("Heart disease")
                if avg_glucose_level > 140:
                    risk_factors.append("Elevated glucose levels")
                if bmi > 30:
                    risk_factors.append("Obesity (BMI > 30)")
                if smoking_status == "smokes":
                    risk_factors.append("Current smoker")

                if risk_factors:
                    for factor in risk_factors:
                        st.markdown(f"â€¢ {factor}")
                else:
                    st.markdown("No major risk factors identified.")

                st.markdown("</div>", unsafe_allow_html=True)

                # Recommendations
                if risk_level in ["Medium", "High"]:
                    st.markdown("<div class='highlight'>", unsafe_allow_html=True)
                    st.markdown("<h3>Recommendations</h3>", unsafe_allow_html=True)

                    st.markdown("""
                    Based on the risk assessment, consider the following recommendations:

                    1. **Medical Consultation**: Schedule a comprehensive medical check-up
                    2. **Regular Monitoring**: Monitor blood pressure, glucose levels, and other vital signs
                    3. **Lifestyle Changes**: Consider diet modifications, exercise, and smoking cessation if applicable
                    4. **Medication Review**: Discuss current medications with healthcare provider
                    """)

                    st.markdown("</div>", unsafe_allow_html=True)
            except Exception as e:
                st.error(f"Error making prediction: {e}")

    # MODEL PERFORMANCE PAGE
    elif selected_page == "Model Performance":
        st.markdown("<h2 class='sub-header'>Model Performance</h2>", unsafe_allow_html=True)

        st.markdown("<div class='highlight'>", unsafe_allow_html=True)
        st.markdown("""
        StrokeShield combines two powerful machine learning algorithms to achieve high prediction accuracy.
        By leveraging the strengths of both Random Forest and Logistic Regression models, the system achieves
        approximately 90% accuracy in predicting stroke occurrence.
        """)
        st.markdown("</div>", unsafe_allow_html=True)

        # Create tabs for different model metrics
        tab1, tab2, tab3 = st.tabs(["Accuracy Metrics", "Model Comparison", "Technical Details"])

        with tab1:
            # Sample metrics (would be replaced with actual metrics in a real application)
            metrics = {
                "Random Forest": {
                    "Accuracy": 0.91,
                    "Precision": 0.85,
                    "Recall": 0.78,
                    "F1 Score": 0.81,
                    "AUC": 0.88
                },
                "Logistic Regression": {
                    "Accuracy": 0.87,
                    "Precision": 0.79,
                    "Recall": 0.81,
                    "F1 Score": 0.80,
                    "AUC": 0.84
                },
                "Ensemble (Combined)": {
                    "Accuracy": 0.92,
                    "Precision": 0.87,
                    "Recall": 0.83,
                    "F1 Score": 0.85,
                    "AUC": 0.90
                }
            }

            # Display metrics
            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("<h3>Random Forest</h3>", unsafe_allow_html=True)
                for metric, value in metrics["Random Forest"].items():
                    st.metric(metric, f"{value:.2f}")

            with col2:
                st.markdown("<h3>Logistic Regression</h3>", unsafe_allow_html=True)
                for metric, value in metrics["Logistic Regression"].items():
                    st.metric(metric, f"{value:.2f}")

            with col3:
                st.markdown("<h3>Ensemble Model</h3>", unsafe_allow_html=True)
                for metric, value in metrics["Ensemble (Combined)"].items():
                    st.metric(metric, f"{value:.2f}")

        with tab2:
            # Create sample confusion matrix
            fig, axes = plt.subplots(1, 3, figsize=(18, 5))

            # Sample confusion matrices
            # These would be replaced with actual confusion matrices in a real application
            models = ["Random Forest", "Logistic Regression", "Ensemble"]
            cm_data = [
                [[920, 80], [40, 160]],  # Random Forest
                [[900, 100], [30, 170]],  # Logistic Regression
                [[930, 70], [20, 180]]  # Ensemble
            ]

            for i, (model, cm) in enumerate(zip(models, cm_data)):
                sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                            xticklabels=["No Stroke", "Stroke"],
                            yticklabels=["No Stroke", "Stroke"], ax=axes[i])
                axes[i].set_title(f"{model} Confusion Matrix")
                axes[i].set_xlabel("Predicted")
                axes[i].set_ylabel("Actual")

            plt.tight_layout()
            st.pyplot(fig)

            st.markdown("""
            The confusion matrices show the performance of each model in predicting stroke cases.
            - **True Negatives**: Correctly predicted no stroke
            - **False Positives**: Incorrectly predicted stroke
            - **False Negatives**: Incorrectly predicted no stroke
            - **True Positives**: Correctly predicted stroke

            The ensemble model shows improved performance by reducing both false positives and false negatives.
            """)

        with tab3:
            st.markdown("<h3>Technical Implementation Details</h3>", unsafe_allow_html=True)

            st.markdown("""
            ### Data Preprocessing
            - **Missing Values**: Handled using median imputation for numeric features and mode imputation for categorical features
            - **Categorical Encoding**: One-hot encoding applied to categorical features
            - **Feature Scaling**: Standard scaling applied to numeric features

            ### Random Forest Configuration
            - **Estimators**: 200 decision trees
            - **Max Depth**: 20 levels per tree
            - **Min Samples Split**: 5 samples required to split internal node
            - **Min Samples Leaf**: 2 samples required at leaf node
            - **Feature Selection**: Automatic feature selection based on importance

            ### Logistic Regression Configuration
            - **Regularization**: L2 regularization with C=1.0
            - **Solver**: 'liblinear' optimizer for small datasets
            - **Max Iterations**: 1000 iterations for convergence

            ### Ensemble Method
            - **Combination Technique**: Probability averaging of both models
            - **Threshold**: 0.5 probability threshold for positive classification
            """)


# Run the application
if __name__ == "__main__":
    main()